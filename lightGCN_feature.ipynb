{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import required modules\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, Tensor\n",
    "\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "\n",
    "from torch_geometric.utils import structured_negative_sampling\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.typing import Adj\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MovieLens dataset\n",
    "from torch_geometric.datasets import MovieLens100K, MovieLens1M, AmazonBook\n",
    "\n",
    "dataset = MovieLens100K(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  movie={ x=[1682, 18] },\n",
       "  user={ x=[943, 24] },\n",
       "  (user, rates, movie)={\n",
       "    edge_index=[2, 80000],\n",
       "    rating=[80000],\n",
       "    time=[80000],\n",
       "    edge_label_index=[2, 20000],\n",
       "    edge_label=[20000],\n",
       "  },\n",
       "  (movie, rated_by, user)={\n",
       "    edge_index=[2, 80000],\n",
       "    rating=[80000],\n",
       "    time=[80000],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset[0]  # Get the graph data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_users:  943\n",
      "num_items:  1682\n",
      "edge index:  tensor([[   0,    0,    0,  ...,  942,  942,  942],\n",
      "        [   0,    1,    2,  ..., 1187, 1227, 1329]])\n",
      "edge label:  tensor([5., 3., 5.,  ..., 3., 3., 5.])\n"
     ]
    }
   ],
   "source": [
    "num_users = data.num_nodes_dict['user']\n",
    "print(\"num_users: \", num_users)\n",
    "\n",
    "num_movies = data.num_nodes_dict['movie']\n",
    "print(\"num_items: \", num_movies)\n",
    "\n",
    "edge_index = data['user', 'rates', 'movie'].edge_index\n",
    "print(\"edge index: \", edge_index)\n",
    "\n",
    "edge_label = data['user', 'rates', 'movie'].edge_label\n",
    "print(\"edge label: \", edge_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:  torch.Size([2, 80000])\n",
      "val data:  torch.Size([2, 20000])\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train/validation/test sets\n",
    "\n",
    "train_edge_index = data['user', 'rates', 'movie'].edge_index\n",
    "val_edge_index = data['user', 'rates', 'movie'].edge_label_index\n",
    "\n",
    "print(\"train data: \", train_edge_index.size())\n",
    "print(\"val data: \", val_edge_index.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert edge indices into Sparse Tensors: https://pytorch-geometric.readthedocs.io/en/latest/notes/sparse_tensor.html\n",
    "train_sparse_edge_index = SparseTensor(row=train_edge_index[0], col=train_edge_index[1], sparse_sizes=(\n",
    "    num_users + num_movies, num_users + num_movies))\n",
    "val_sparse_edge_index = SparseTensor(row=val_edge_index[0], col=val_edge_index[1], sparse_sizes=(\n",
    "    num_users + num_movies, num_users + num_movies))\n",
    "# test_sparse_edge_index = SparseTensor(row=test_edge_index[0], col=test_edge_index[1], sparse_sizes=(\n",
    "#     num_users + num_movies, num_users + num_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function which random samples a mini-batch of positive and negative samples\n",
    "def sample_mini_batch(batch_size, edge_index):\n",
    "    \"\"\"Randomly samples indices of a minibatch given an adjacency matrix\n",
    "\n",
    "    Args:\n",
    "        batch_size (int): minibatch size\n",
    "        edge_index (torch.Tensor): 2 by N list of edges\n",
    "\n",
    "    Returns:\n",
    "        tuple: user indices, positive item indices, negative item indices\n",
    "    \"\"\"\n",
    "    edges = structured_negative_sampling(edge_index)\n",
    "    edges = torch.stack(edges, dim=0)\n",
    "    indices = random.choices(\n",
    "        [i for i in range(edges[0].shape[0])], k=batch_size)\n",
    "    batch = edges[:, indices]\n",
    "    user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
    "    return user_indices, pos_item_indices, neg_item_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Feature Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines LightGCN model\n",
    "class LightGCN(MessagePassing):\n",
    "    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64, K=3, add_self_loops=False):\n",
    "        \"\"\"Initializes LightGCN Model\n",
    "\n",
    "        Args:\n",
    "            num_users (int): Number of users\n",
    "            num_items (int): Number of items\n",
    "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
    "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
    "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_users, self.num_items = num_users, num_items\n",
    "        self.embedding_dim, self.K = embedding_dim, K\n",
    "        self.add_self_loops = add_self_loops\n",
    "        \n",
    "        user_feat_dim = 24\n",
    "        movie_feat_dim = 18\n",
    "\n",
    "        # Learnable embeddings for users and movies\n",
    "        self.users_emb = torch.nn.Embedding(num_users, embedding_dim)\n",
    "        self.items_emb = torch.nn.Embedding(num_movies, embedding_dim)\n",
    "        nn.init.xavier_normal_(self.users_emb.weight)\n",
    "        nn.init.xavier_normal_(self.items_emb.weight)\n",
    "        # Project user and movie features to the hidden dimension\n",
    "        user_lin = torch.nn.Linear(user_feat_dim, embedding_dim)\n",
    "        movie_lin = torch.nn.Linear(movie_feat_dim, embedding_dim)\n",
    "\n",
    "        self.user_final = user_lin(data[\"user\"].x) + self.users_emb.weight # Combine user features and embeddings\n",
    "        self.movie_final = movie_lin(data[\"movie\"].x) + self.items_emb.weight\n",
    "\n",
    "    def forward(self, edge_index: SparseTensor):\n",
    "        \"\"\"Forward propagation of LightGCN Model.\n",
    "\n",
    "        Args:\n",
    "            edge_index (SparseTensor): adjacency matrix\n",
    "\n",
    "        Returns:\n",
    "            tuple (Tensor): e_u_k, e_u_0, e_i_k, e_i_0\n",
    "        \"\"\"\n",
    "        # compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
    "        edge_index_norm = gcn_norm(\n",
    "            edge_index, add_self_loops=self.add_self_loops)\n",
    "\n",
    "        emb_0 = torch.cat([self.user_final, self.movie_final]) # E^0\n",
    "        embs = [emb_0]\n",
    "        emb_k = emb_0\n",
    "\n",
    "        # multi-scale diffusion\n",
    "        for i in range(self.K):\n",
    "            emb_k = self.propagate(edge_index_norm, x=emb_k)\n",
    "            embs.append(emb_k)\n",
    "        ################\n",
    "        alpha = 1 / (1 + self.K) \n",
    "        self.embs_weighted = [emb * alpha for emb in embs]\n",
    "        embs = torch.stack(self.embs_weighted, dim=1)\n",
    "        emb_final = torch.mean(embs, dim=1) # E^K\n",
    "\n",
    "        users_emb_final, items_emb_final = torch.split(\n",
    "            emb_final, [self.num_users, self.num_items]) # splits into e_u^K and e_i^K\n",
    "\n",
    "        # returns e_u^K, e_u^0, e_i^K, e_i^0\n",
    "        return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n",
    "\n",
    "    def message(self, x_j: Tensor) -> Tensor:\n",
    "        return x_j\n",
    "\n",
    "    def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
    "        # computes \\tilde{A} @ x\n",
    "        return matmul(adj_t, x)\n",
    "\n",
    "model = LightGCN(num_users, num_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, lambda_val):\n",
    "    \"\"\"Bayesian Personalized Ranking Loss as described in https://arxiv.org/abs/1205.2618\n",
    "\n",
    "    Args:\n",
    "        users_emb_final (torch.Tensor): e_u_k\n",
    "        users_emb_0 (torch.Tensor): e_u_0\n",
    "        pos_items_emb_final (torch.Tensor): positive e_i_k\n",
    "        pos_items_emb_0 (torch.Tensor): positive e_i_0\n",
    "        neg_items_emb_final (torch.Tensor): negative e_i_k\n",
    "        neg_items_emb_0 (torch.Tensor): negative e_i_0\n",
    "        lambda_val (float): lambda value for regularization loss term\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: scalar bpr loss value\n",
    "    \"\"\"\n",
    "    reg_loss = lambda_val * (users_emb_0.norm(2).pow(2) +\n",
    "                             pos_items_emb_0.norm(2).pow(2) +\n",
    "                             neg_items_emb_0.norm(2).pow(2)) # L2 loss\n",
    "\n",
    "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
    "    pos_scores = torch.sum(pos_scores, dim=-1) # predicted scores of positive samples\n",
    "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
    "    neg_scores = torch.sum(neg_scores, dim=-1) # predicted scores of negative samples\n",
    "\n",
    "    loss = -torch.mean(torch.nn.functional.softplus(pos_scores - neg_scores)) + reg_loss\n",
    "    #loss = -torch.log(torch.sigmoid(pos_scores - neg_scores)).mean()\n",
    "    #loss = -torch.mean(torch.log(F.sigmoid(pos_scores - neg_scores)),0)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to get N_u\n",
    "def get_user_positive_items(edge_index):\n",
    "    \"\"\"Generates dictionary of positive items for each user\n",
    "\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): 2 by N list of edges\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionary of positive items for each user\n",
    "    \"\"\"\n",
    "    user_pos_items = {}\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        user = edge_index[0][i].item()\n",
    "        item = edge_index[1][i].item()\n",
    "        if user not in user_pos_items:\n",
    "            user_pos_items[user] = []\n",
    "        user_pos_items[user].append(item)\n",
    "    return user_pos_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes recall@K and precision@K\n",
    "def RecallPrecision_ATk(groundTruth, r, k):\n",
    "    \"\"\"Computers recall @ k and precision @ k\n",
    "\n",
    "    Args:\n",
    "        groundTruth (list): list of lists containing highly rated items of each user\n",
    "        r (list): list of lists indicating whether each top k item recommended to each user\n",
    "            is a top k ground truth item or not\n",
    "        k (intg): determines the top k items to compute precision and recall on\n",
    "\n",
    "    Returns:\n",
    "        tuple: recall @ k, precision @ k\n",
    "    \"\"\"\n",
    "    num_correct_pred = torch.sum(r, dim=-1)  # number of correctly predicted items per user\n",
    "    # number of items liked by each user in the test set\n",
    "    user_num_liked = torch.Tensor([len(groundTruth[i])\n",
    "                                  for i in range(len(groundTruth))])\n",
    "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
    "    precision = torch.mean(num_correct_pred) / k\n",
    "    return recall.item(), precision.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes NDCG@K\n",
    "def NDCGatK_r(groundTruth, r, k):\n",
    "    \"\"\"Computes Normalized Discounted Cumulative Gain (NDCG) @ k\n",
    "\n",
    "    Args:\n",
    "        groundTruth (list): list of lists containing highly rated items of each user\n",
    "        r (list): list of lists indicating whether each top k item recommended to each user\n",
    "            is a top k ground truth item or not\n",
    "        k (int): determines the top k items to compute ndcg on\n",
    "\n",
    "    Returns:\n",
    "        float: ndcg @ k\n",
    "    \"\"\"\n",
    "    assert len(r) == len(groundTruth)\n",
    "\n",
    "    test_matrix = torch.zeros((len(r), k))\n",
    "\n",
    "    for i, items in enumerate(groundTruth):\n",
    "        length = min(len(items), k)\n",
    "        test_matrix[i, :length] = 1\n",
    "    max_r = test_matrix\n",
    "    idcg = torch.sum(max_r * 1. / torch.log2(torch.arange(2, k + 2)), axis=1)\n",
    "    dcg = r * (1. / torch.log2(torch.arange(2, k + 2)))\n",
    "    dcg = torch.sum(dcg, axis=1)\n",
    "    idcg[idcg == 0.] = 1.\n",
    "    ndcg = dcg / idcg\n",
    "    ndcg[torch.isnan(ndcg)] = 0.\n",
    "    return torch.mean(ndcg).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function to get evaluation metrics\n",
    "def get_metrics(model, edge_index, exclude_edge_indices, k):\n",
    "    \"\"\"Computes the evaluation metrics: recall, precision, and ndcg @ k\n",
    "\n",
    "    Args:\n",
    "        model (LighGCN): lightgcn model\n",
    "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
    "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
    "        k (int): determines the top k items to compute metrics on\n",
    "\n",
    "    Returns:\n",
    "        tuple: recall @ k, precision @ k, ndcg @ k\n",
    "    \"\"\"\n",
    "    user_embedding = model.users_emb.weight\n",
    "    item_embedding = model.items_emb.weight\n",
    "\n",
    "    # get ratings between every user and item - shape is num users x num movies\n",
    "    rating = torch.matmul(user_embedding, item_embedding.T)\n",
    "\n",
    "    for exclude_edge_index in exclude_edge_indices:\n",
    "        # gets all the positive items for each user from the edge index\n",
    "        user_pos_items = get_user_positive_items(exclude_edge_index)\n",
    "        # get coordinates of all edges to exclude\n",
    "        exclude_users = []\n",
    "        exclude_items = []\n",
    "        for user, items in user_pos_items.items():\n",
    "            exclude_users.extend([user] * len(items))\n",
    "            exclude_items.extend(items)\n",
    "\n",
    "        # set ratings of excluded edges to large negative value\n",
    "        rating[exclude_users, exclude_items] = -(1 << 10)\n",
    "\n",
    "    # get the top k recommended items for each user\n",
    "    _, top_K_items = torch.topk(rating, k=k)\n",
    "\n",
    "    # get all unique users in evaluated split\n",
    "    users = edge_index[0].unique()\n",
    "\n",
    "    test_user_pos_items = get_user_positive_items(edge_index)\n",
    "\n",
    "    # convert test user pos items dictionary into a list\n",
    "    test_user_pos_items_list = [\n",
    "        test_user_pos_items[user.item()] for user in users]\n",
    "\n",
    "    # determine the correctness of topk predictions\n",
    "    r = []\n",
    "    for user in users:\n",
    "        ground_truth_items = test_user_pos_items[user.item()]\n",
    "        label = list(map(lambda x: x in ground_truth_items, top_K_items[user]))\n",
    "        r.append(label)\n",
    "    r = torch.Tensor(np.array(r).astype('float'))\n",
    "\n",
    "    recall, precision = RecallPrecision_ATk(test_user_pos_items_list, r, k)\n",
    "    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n",
    "\n",
    "    return recall, precision, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function to evaluate model\n",
    "def evaluation(model, edge_index, sparse_edge_index, exclude_edge_indices, k, lambda_val):\n",
    "    \"\"\"Evaluates model loss and metrics including recall, precision, ndcg @ k\n",
    "\n",
    "    Args:\n",
    "        model (LighGCN): lightgcn model\n",
    "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
    "        sparse_edge_index (sparseTensor): sparse adjacency matrix for split to evaluate\n",
    "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
    "        k (int): determines the top k items to compute metrics on\n",
    "        lambda_val (float): determines lambda for bpr loss\n",
    "\n",
    "    Returns:\n",
    "        tuple: bpr loss, recall @ k, precision @ k, ndcg @ k\n",
    "    \"\"\"\n",
    "    # get embeddings\n",
    "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
    "        sparse_edge_index)\n",
    "    edges = structured_negative_sampling(\n",
    "        edge_index, contains_neg_self_loops=False)\n",
    "    user_indices, pos_item_indices, neg_item_indices = edges[0], edges[1], edges[2]\n",
    "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
    "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
    "        pos_item_indices], items_emb_0[pos_item_indices]\n",
    "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
    "        neg_item_indices], items_emb_0[neg_item_indices]\n",
    "\n",
    "    loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0,\n",
    "                    neg_items_emb_final, neg_items_emb_0, lambda_val).item()\n",
    "\n",
    "    recall, precision, ndcg = get_metrics(\n",
    "        model, edge_index, exclude_edge_indices, k)\n",
    "\n",
    "    return loss, recall, precision, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define contants\n",
    "ITERATIONS = 10000\n",
    "BATCH_SIZE = 1024\n",
    "LR = 1e-3\n",
    "ITERS_PER_EVAL = 200\n",
    "ITERS_PER_LR_DECAY = 200\n",
    "K = 20\n",
    "LAMBDA = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu.\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device {device}.\")\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "edge_index = edge_index.to(device)\n",
    "train_edge_index = train_edge_index.to(device)\n",
    "train_sparse_edge_index = train_sparse_edge_index.to(device)\n",
    "\n",
    "val_edge_index = val_edge_index.to(device)\n",
    "val_sparse_edge_index = val_sparse_edge_index.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 0/10000] train_loss: -0.67114, val_loss: -0.68785, val_recall@20: 0.01455, val_precision@20: 0.03017, val_ndcg@20: 0.03278\n",
      "[Iteration 200/10000] train_loss: -0.69265, val_loss: -0.69291, val_recall@20: 0.01435, val_precision@20: 0.04695, val_ndcg@20: 0.04744\n",
      "[Iteration 400/10000] train_loss: -0.69262, val_loss: -0.69286, val_recall@20: 0.00754, val_precision@20: 0.02691, val_ndcg@20: 0.02847\n",
      "[Iteration 600/10000] train_loss: -0.69261, val_loss: -0.69284, val_recall@20: 0.00692, val_precision@20: 0.02309, val_ndcg@20: 0.02372\n",
      "[Iteration 800/10000] train_loss: -0.6926, val_loss: -0.69282, val_recall@20: 0.00712, val_precision@20: 0.02691, val_ndcg@20: 0.02847\n",
      "[Iteration 1000/10000] train_loss: -0.6926, val_loss: -0.69281, val_recall@20: 0.00715, val_precision@20: 0.0244, val_ndcg@20: 0.02517\n",
      "[Iteration 1200/10000] train_loss: -0.6926, val_loss: -0.69282, val_recall@20: 0.00585, val_precision@20: 0.01993, val_ndcg@20: 0.02101\n",
      "[Iteration 1400/10000] train_loss: -0.69259, val_loss: -0.69282, val_recall@20: 0.00644, val_precision@20: 0.02593, val_ndcg@20: 0.02683\n",
      "[Iteration 1600/10000] train_loss: -0.69259, val_loss: -0.6928, val_recall@20: 0.0079, val_precision@20: 0.02636, val_ndcg@20: 0.02691\n",
      "[Iteration 1800/10000] train_loss: -0.69259, val_loss: -0.69282, val_recall@20: 0.00862, val_precision@20: 0.02767, val_ndcg@20: 0.02994\n",
      "[Iteration 2000/10000] train_loss: -0.69259, val_loss: -0.69281, val_recall@20: 0.00759, val_precision@20: 0.02669, val_ndcg@20: 0.02651\n",
      "[Iteration 2200/10000] train_loss: -0.6926, val_loss: -0.69281, val_recall@20: 0.00719, val_precision@20: 0.02647, val_ndcg@20: 0.02735\n",
      "[Iteration 2400/10000] train_loss: -0.6926, val_loss: -0.69281, val_recall@20: 0.00667, val_precision@20: 0.02331, val_ndcg@20: 0.02413\n",
      "[Iteration 2600/10000] train_loss: -0.6926, val_loss: -0.69281, val_recall@20: 0.00656, val_precision@20: 0.02397, val_ndcg@20: 0.02571\n",
      "[Iteration 2800/10000] train_loss: -0.6926, val_loss: -0.69281, val_recall@20: 0.00636, val_precision@20: 0.02277, val_ndcg@20: 0.02275\n",
      "[Iteration 3000/10000] train_loss: -0.6926, val_loss: -0.69281, val_recall@20: 0.00765, val_precision@20: 0.02516, val_ndcg@20: 0.02677\n",
      "[Iteration 3200/10000] train_loss: -0.69259, val_loss: -0.69281, val_recall@20: 0.00734, val_precision@20: 0.028, val_ndcg@20: 0.02881\n",
      "[Iteration 3400/10000] train_loss: -0.69261, val_loss: -0.69281, val_recall@20: 0.00854, val_precision@20: 0.02778, val_ndcg@20: 0.0295\n",
      "[Iteration 3600/10000] train_loss: -0.69259, val_loss: -0.69281, val_recall@20: 0.00899, val_precision@20: 0.03235, val_ndcg@20: 0.03354\n",
      "[Iteration 3800/10000] train_loss: -0.69259, val_loss: -0.69281, val_recall@20: 0.00822, val_precision@20: 0.02418, val_ndcg@20: 0.02666\n",
      "[Iteration 4000/10000] train_loss: -0.69259, val_loss: -0.69281, val_recall@20: 0.00853, val_precision@20: 0.02647, val_ndcg@20: 0.0278\n",
      "[Iteration 4200/10000] train_loss: -0.69259, val_loss: -0.6928, val_recall@20: 0.00699, val_precision@20: 0.02309, val_ndcg@20: 0.02406\n",
      "[Iteration 4400/10000] train_loss: -0.6926, val_loss: -0.69281, val_recall@20: 0.00832, val_precision@20: 0.02484, val_ndcg@20: 0.02638\n",
      "[Iteration 4600/10000] train_loss: -0.69259, val_loss: -0.69281, val_recall@20: 0.00965, val_precision@20: 0.02691, val_ndcg@20: 0.02889\n",
      "[Iteration 4800/10000] train_loss: -0.6926, val_loss: -0.69281, val_recall@20: 0.00663, val_precision@20: 0.02146, val_ndcg@20: 0.0229\n",
      "[Iteration 5000/10000] train_loss: -0.69259, val_loss: -0.69281, val_recall@20: 0.00858, val_precision@20: 0.0219, val_ndcg@20: 0.0244\n",
      "[Iteration 5200/10000] train_loss: -0.6926, val_loss: -0.69281, val_recall@20: 0.00665, val_precision@20: 0.02516, val_ndcg@20: 0.02612\n",
      "[Iteration 5400/10000] train_loss: -0.6926, val_loss: -0.69282, val_recall@20: 0.0081, val_precision@20: 0.02702, val_ndcg@20: 0.02836\n",
      "[Iteration 5600/10000] train_loss: -0.6926, val_loss: -0.69281, val_recall@20: 0.00846, val_precision@20: 0.0268, val_ndcg@20: 0.02869\n",
      "[Iteration 5800/10000] train_loss: -0.6926, val_loss: -0.69281, val_recall@20: 0.0085, val_precision@20: 0.02495, val_ndcg@20: 0.02678\n",
      "[Iteration 6000/10000] train_loss: -0.69258, val_loss: -0.69281, val_recall@20: 0.00838, val_precision@20: 0.02756, val_ndcg@20: 0.02952\n",
      "[Iteration 6200/10000] train_loss: -0.6926, val_loss: -0.69282, val_recall@20: 0.00759, val_precision@20: 0.02756, val_ndcg@20: 0.02996\n",
      "[Iteration 6400/10000] train_loss: -0.6926, val_loss: -0.69281, val_recall@20: 0.00726, val_precision@20: 0.02462, val_ndcg@20: 0.02596\n",
      "[Iteration 6600/10000] train_loss: -0.69259, val_loss: -0.69281, val_recall@20: 0.00647, val_precision@20: 0.02037, val_ndcg@20: 0.02194\n",
      "[Iteration 6800/10000] train_loss: -0.69259, val_loss: -0.69281, val_recall@20: 0.00798, val_precision@20: 0.02636, val_ndcg@20: 0.02916\n",
      "[Iteration 7000/10000] train_loss: -0.69259, val_loss: -0.69281, val_recall@20: 0.00728, val_precision@20: 0.02309, val_ndcg@20: 0.02554\n",
      "[Iteration 7200/10000] train_loss: -0.6926, val_loss: -0.69281, val_recall@20: 0.00767, val_precision@20: 0.02495, val_ndcg@20: 0.02645\n",
      "[Iteration 7400/10000] train_loss: -0.6926, val_loss: -0.69281, val_recall@20: 0.00678, val_precision@20: 0.02015, val_ndcg@20: 0.02201\n",
      "[Iteration 7600/10000] train_loss: -0.69258, val_loss: -0.69281, val_recall@20: 0.00795, val_precision@20: 0.02484, val_ndcg@20: 0.02718\n",
      "[Iteration 7800/10000] train_loss: -0.6926, val_loss: -0.69281, val_recall@20: 0.00612, val_precision@20: 0.02168, val_ndcg@20: 0.02343\n",
      "[Iteration 8000/10000] train_loss: -0.6926, val_loss: -0.69282, val_recall@20: 0.00684, val_precision@20: 0.02309, val_ndcg@20: 0.02447\n",
      "[Iteration 8200/10000] train_loss: -0.69259, val_loss: -0.69281, val_recall@20: 0.00765, val_precision@20: 0.02473, val_ndcg@20: 0.02529\n",
      "[Iteration 8400/10000] train_loss: -0.6926, val_loss: -0.69282, val_recall@20: 0.00839, val_precision@20: 0.02734, val_ndcg@20: 0.02934\n",
      "[Iteration 8600/10000] train_loss: -0.69259, val_loss: -0.69281, val_recall@20: 0.0086, val_precision@20: 0.02702, val_ndcg@20: 0.02953\n",
      "[Iteration 8800/10000] train_loss: -0.6926, val_loss: -0.69281, val_recall@20: 0.00745, val_precision@20: 0.02397, val_ndcg@20: 0.0255\n",
      "[Iteration 9000/10000] train_loss: -0.69259, val_loss: -0.69281, val_recall@20: 0.00674, val_precision@20: 0.02266, val_ndcg@20: 0.02367\n",
      "[Iteration 9200/10000] train_loss: -0.69259, val_loss: -0.69281, val_recall@20: 0.00733, val_precision@20: 0.02233, val_ndcg@20: 0.02367\n",
      "[Iteration 9400/10000] train_loss: -0.6926, val_loss: -0.69281, val_recall@20: 0.00866, val_precision@20: 0.02353, val_ndcg@20: 0.02616\n",
      "[Iteration 9600/10000] train_loss: -0.69259, val_loss: -0.69282, val_recall@20: 0.008, val_precision@20: 0.02407, val_ndcg@20: 0.02658\n",
      "[Iteration 9800/10000] train_loss: -0.6926, val_loss: -0.69282, val_recall@20: 0.00765, val_precision@20: 0.0244, val_ndcg@20: 0.0257\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for iter in range(ITERATIONS):\n",
    "    # forward propagation\n",
    "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
    "        train_sparse_edge_index)\n",
    "\n",
    "    # mini batching\n",
    "    #user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(BATCH_SIZE, train_edge_index)\n",
    "    edges = structured_negative_sampling(\n",
    "        edge_index, contains_neg_self_loops=False)\n",
    "    user_indices, pos_item_indices, neg_item_indices = edges[0], edges[1], edges[2]\n",
    "    user_indices, pos_item_indices, neg_item_indices = user_indices.to(\n",
    "        device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
    "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
    "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
    "        pos_item_indices], items_emb_0[pos_item_indices]\n",
    "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
    "        neg_item_indices], items_emb_0[neg_item_indices]\n",
    "\n",
    "    # loss computation\n",
    "    train_loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final,\n",
    "                          pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, LAMBDA)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "\n",
    "    if iter % ITERS_PER_EVAL == 0:\n",
    "        model.eval()\n",
    "        val_loss, recall, precision, ndcg = evaluation(\n",
    "            model, val_edge_index, val_sparse_edge_index, [train_edge_index], K, LAMBDA)\n",
    "        print(f\"[Iteration {iter}/{ITERATIONS}] train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_recall@{K}: {round(recall, 5)}, val_precision@{K}: {round(precision, 5)}, val_ndcg@{K}: {round(ndcg, 5)}\")\n",
    "        train_losses.append(train_loss.item())\n",
    "        val_losses.append(val_loss)\n",
    "        model.train()\n",
    "\n",
    "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iters = [iter * ITERS_PER_EVAL for iter in range(len(train_losses))]\n",
    "plt.plot(iters, train_losses, label='train')\n",
    "plt.plot(iters, val_losses, label='validation')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.title('training and validation loss curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_edge_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# evaluate on test set\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m----> 3\u001b[0m test_edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mtest_edge_index\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m test_sparse_edge_index \u001b[38;5;241m=\u001b[39m test_sparse_edge_index\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m test_loss, test_recall, test_precision, test_ndcg \u001b[38;5;241m=\u001b[39m evaluation(\n\u001b[1;32m      7\u001b[0m             model, test_edge_index, test_sparse_edge_index, [train_edge_index, val_edge_index], K, LAMBDA)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_edge_index' is not defined"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "model.eval()\n",
    "test_edge_index = test_edge_index.to(device)\n",
    "test_sparse_edge_index = test_sparse_edge_index.to(device)\n",
    "\n",
    "test_loss, test_recall, test_precision, test_ndcg = evaluation(\n",
    "            model, test_edge_index, test_sparse_edge_index, [train_edge_index, val_edge_index], K, LAMBDA)\n",
    "\n",
    "print(f\"[test_loss: {round(test_loss, 5)}, test_recall@{K}: {round(test_recall, 5)}, test_precision@{K}: {round(test_precision, 5)}, test_ndcg@{K}: {round(test_ndcg, 5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "df = pd.read_csv(movie_path)\n",
    "movieid_title = pd.Series(df.title.values,index=df.movieId).to_dict()\n",
    "movieid_genres = pd.Series(df.genres.values,index=df.movieId).to_dict()\n",
    "\n",
    "user_pos_items = get_user_positive_items(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(user_id, num_recs):\n",
    "    user = user_mapping[user_id]\n",
    "    e_u = model.users_emb.weight[user]\n",
    "    scores = model.items_emb.weight @ e_u\n",
    "\n",
    "    values, indices = torch.topk(scores, k=len(user_pos_items[user]) + num_recs)\n",
    "\n",
    "    movies = [index.cpu().item() for index in indices if index in user_pos_items[user]][:num_recs]\n",
    "    movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values()).index(movie)] for movie in movies]\n",
    "    titles = [movieid_title[id] for id in movie_ids]\n",
    "    genres = [movieid_genres[id] for id in movie_ids]\n",
    "\n",
    "    print(f\"Here are some movies that user {user_id} rated highly\")\n",
    "    for i in range(num_recs):\n",
    "        print(f\"title: {titles[i]}, genres: {genres[i]} \")\n",
    "\n",
    "    print()\n",
    "\n",
    "    movies = [index.cpu().item() for index in indices if index not in user_pos_items[user]][:num_recs]\n",
    "    movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values()).index(movie)] for movie in movies]\n",
    "    titles = [movieid_title[id] for id in movie_ids]\n",
    "    genres = [movieid_genres[id] for id in movie_ids]\n",
    "\n",
    "    print(f\"Here are some suggested movies for user {user_id}\")\n",
    "    for i in range(num_recs):\n",
    "        print(f\"title: {titles[i]}, genres: {genres[i]} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_ID = 1\n",
    "NUM_RECS = 10\n",
    "\n",
    "make_predictions(USER_ID, NUM_RECS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
